name: Spider

on:
  schedule:
    - cron: "*/45 10 * * *"
  workflow_dispatch:


jobs:
  spider:
    runs-on: ubuntu-latest
    steps:
      - name: checkout
        uses: actions/checkout@v2

      - name: 'Set up Python'
        uses: actions/setup-python@v2
        with:
          python-version: 3.8

      - name: Run a single-line script
        run: |
          pip install scrapy

      - name: Delete old file scrapy_output.txt
        run: |
          rm -f /tmp/scrapy_output.txt

      - name: Delete old file rest2.html
        run: |
          rm -f rest2.html

      - name: Run a scrapy crawl
        run: |
          scrapy crawl rest

      - name: Run a script to generate rest2.html
        run: |
          python generate.py < /tmp/scrapy_output.txt > rest2.html

      - name: Copy file to S3
        uses: qoqa/action-s3-cp@v1.1
        env:
          AWS_S3_BUCKET: ${{ secrets.BUCKET_NAME }}
          AWS_ACCESS_KEY_ID: ${{ secrets.ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.ACCESS_KEY }}
          AWS_REGION: 'ap-southeast-2'
          AWS_S3_PATH: ${{ secrets.S3_PATH }}
          FILE: 'rest2.html' 

      - name: Commit report
        run: |
          git config --global user.name 'sdesirazu'
          git config --global user.email 'sdesirazu@users.noreply.github.com'
          git commit -am "Automated report"
          git push
